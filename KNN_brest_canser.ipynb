{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " n_neighbors=1\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n",
      "(285, 30)\n",
      "(284, 30)\n",
      "0.9333333333333333\n",
      "\n",
      " n_neighbors=3\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "(285, 30)\n",
      "(284, 30)\n",
      "0.9368421052631579\n",
      "\n",
      " n_neighbors=5\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "(285, 30)\n",
      "(284, 30)\n",
      "0.9578947368421052\n",
      "\n",
      " n_neighbors=7\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "(285, 30)\n",
      "(284, 30)\n",
      "0.9473684210526315\n",
      "\n",
      " n_neighbors=9\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "           weights='uniform')\n",
      "(285, 30)\n",
      "(284, 30)\n",
      "0.9578947368421052\n",
      "\n",
      " n_neighbors=11\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
      "           weights='uniform')\n",
      "(285, 30)\n",
      "(284, 30)\n",
      "0.9614035087719298\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from numpy import linalg as LA\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# In this example we use iris data set used from sklearn. sklearn provides toy datasets through packages which we\n",
    "# can import. The imported data is not separated as train_data, train_labels, test_data and test_labels. We use\n",
    "# test_train_split from model_selection package and split the data. One parameter to look for is the test_size, it is\n",
    "# split of the test data and train data. The argument 0.33 says that the data is divided in the proportions of\n",
    "# 66.66 % train data and 33.33 % test data.\n",
    "\n",
    "iris = datasets.load_breast_cancer()\n",
    "features = iris.data\n",
    "classs = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(features,classs, test_size=0.50, random_state=42)\n",
    "#print(x_train.size)\n",
    "#print(x_train)\n",
    "#print(y_train.size)\n",
    "#print(y_train)\n",
    "'''\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "train_data = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "test_data = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "n_neighbors = [1,3,5,7,9,11]\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for n in n_neighbors:\n",
    "\n",
    "    \n",
    "    \n",
    "    x_min, x_max = train_data[:, 0].min() - 1, train_data[:, 0].max() + 1\n",
    "    y_min, y_max = train_data[:, 1].min() - 1, train_data[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(train_data[:, 0], train_data[:, 1], c=test_data, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i)\"% (n))\n",
    "'''\n",
    "n_neighbors = [1,3,5,7,9,11]\n",
    "for n in n_neighbors:\n",
    "    print(\"\\n n_neighbors=\"+str(n))   \n",
    "    clf = KNeighborsClassifier(n)\n",
    "    clf.fit(x_train, y_train)  \n",
    "    print(clf.fit(x_train, y_train) )\n",
    "    #plt.plot(y_test,y_test)\n",
    "    print(x_test.shape)\n",
    "    print(x_train.shape)\n",
    "    pred=clf.predict(x_test)\n",
    "    print(accuracy_score(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
